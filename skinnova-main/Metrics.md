# Skinnova LLM & API Metrics Used

This document lists all metrics collected for LLM observability, hallucination detection, token usage, GCP Vertex AI , and FastAPI tracing.

---

## LLM Core Metrics

| Metric | Description |
|------|------------|
| `llm.chats.total` | Total number of LLM chat interactions |
| `llm.request.latency` | Latency of LLM requests |
| `llm.tokens.in` | Input tokens sent to the LLM |
| `llm.tokens.out` | Output tokens generated by the LLM |
| `llm.event.llm_chat_called` | Event fired when an LLM chat is invoked |

### Latency Aggregates
- `llm.request.latency.avg`
- `llm.request.latency.median`
- `llm.request.latency.max`
- `llm.request.latency.count`
- `llm.request.latency.95percentile`

---

## LLM Observability Metrics

Tracked at span level via Datadog LLM Observability.

### Input
- `ml_obs.span.llm.input.tokens`
- `ml_obs.span.llm.input.characters`
- `ml_obs.span.llm.input.cost`
- `ml_obs.span.llm.input.non_cached.cost`
- `ml_obs.span.llm.prompt.tokens`

### Output
- `ml_obs.span.llm.output.tokens`
- `ml_obs.span.llm.output.characters`
- `ml_obs.span.llm.output.cost`

### Totals
- `ml_obs.span.llm.total.tokens`
- `ml_obs.span.llm.total.cost`
- `ml_obs.span.llm.completion.tokens`

---

## Hallucination Detection Metrics

| Metric | Description |
|------|------------|
| `llm.hallucination.score` | Hallucination confidence score |
| `llm.hallucination.category` | Category of hallucination detected |
| `llm.hallucination.reason` | Explanation for hallucination |
| `llm.hallucination.blast_radius` | Potential impact scope |
| `llm.hallucination.persona_risk_weight` | Persona-based risk weighting |

### Hallucination Counters
- `llm.hallucination.evaluated.count`
- `llm.hallucination.flagged.count`
- `llm.hallucination.clean.count`
- `llm.hallucination.evaluation_rate`
- `llm.users.affected`
- `llm.evaluation.coverage`

### Errors
- `llm.errors.hallucination_detection_failure`

---

## Prefilter & Safety Triggers

| Metric | Description |
|------|------------|
| `llm.prefilter.score` | Prefilter confidence score |
| `llm.prefilter.trigger` | Indicates prefilter activation |

### Trigger Types
- `llm.prefilter.trigger.medical_claim`
- `llm.prefilter.trigger.absolute_claim`
- `llm.prefilter.trigger.brand_violation`
- `llm.prefilter.trigger.unsafe_ingredient`
- `llm.prefilter.trigger.premature_routine`
- `llm.prefilter.trigger.json_format_violation`

---

## GCP Vertex AI Metrics

### Prediction Volume
- `gcp.aiplatform.prediction.online.prediction_count`
- `gcp.aiplatform.prediction.online.response_count`

### Prediction Latency
- `gcp.aiplatform.prediction.online.prediction_latencies.avg`
- `gcp.aiplatform.prediction.online.prediction_latencies.p95`
- `gcp.aiplatform.prediction.online.prediction_latencies.p99`
- `gcp.aiplatform.prediction.online.prediction_latencies.samplecount`
- `gcp.aiplatform.prediction.online.prediction_latencies.sumsqdev`

### Invocation & Tokens
- `gcp.aiplatform.publisher.online_serving.model_invocation_count`
- `gcp.aiplatform.publisher.online_serving.token_count`
- `gcp.aiplatform.publisher.online_serving.character_count`

### Throughput
- `gcp.aiplatform.publisher.online_serving.consumed_throughput`
- `gcp.aiplatform.publisher.online_serving.consumed_token_throughput`

### Latencies
- `gcp.aiplatform.publisher.online_serving.first_token_latencies.avg`
- `gcp.aiplatform.publisher.online_serving.first_token_latencies.p95`
- `gcp.aiplatform.publisher.online_serving.first_token_latencies.p99`
- `gcp.aiplatform.publisher.online_serving.first_token_latencies.samplecount`
- `gcp.aiplatform.publisher.online_serving.model_invocation_latencies.avg`
- `gcp.aiplatform.publisher.online_serving.model_invocation_latencies.p95`
- `gcp.aiplatform.publisher.online_serving.model_invocation_latencies.p99`
- `gcp.aiplatform.publisher.online_serving.model_invocation_latencies.samplecount`
- `gcp.aiplatform.publisher.online_serving.model_invocation_latencies.sumsqdev`

---

## FastAPI Tracing Metrics

| Metric | Description |
|------|------------|
| `trace.fastapi.request` | Traced FastAPI requests |
| `trace.fastapi.request.hits` | Total request count |
| `trace.fastapi.request.errors` | Request errors |
| `trace.fastapi.request.hits.by_http_status` | Requests by HTTP status |
| `trace.fastapi.request.errors.by_http_status` | Errors by HTTP status |

---

## Notes

- Metrics are emitted via **Datadog Auto LLM Observability Intrumentation + APM + Maunal Span from Backend**
- GCP metrics are sourced from **Google Cloud Integration with Vertex AI using Dataflow Pub/Sub Pipeline**

